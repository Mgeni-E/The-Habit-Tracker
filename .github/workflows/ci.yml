name: Docker CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r habit-tracker/requirements.txt

      - name: Lint with flake8
        run: |
          echo "Running flake8..."
          flake8 habit-tracker/app
          echo "Linting completed."

      - name: Run unit tests
        run: |
          echo "Running pytest with SQLite in-memory..."
          cd habit-tracker
          pytest tests -v --cov=app --cov-report=xml
          echo "Unit tests completed."

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./habit-tracker/coverage.xml
          flags: unittests
          name: codecov-umbrella

  docker-build:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          target: production
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  terraform-plan:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~1.0"

      - name: Validate Required Secrets
        run: |
          if [ -z "${{ secrets.AZURE_CREDENTIALS }}" ]; then
            echo "‚ùå AZURE_CREDENTIALS secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.TF_VAR_FLASK_SECRET_KEY }}" ]; then
            echo "‚ùå TF_VAR_FLASK_SECRET_KEY secret is not set"
            exit 1
          fi
          echo "‚úÖ Required secrets are configured"

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Terraform Plan with Import Handling
        working-directory: terraform
        env:
          TF_VAR_flask_secret_key: ${{ secrets.TF_VAR_FLASK_SECRET_KEY }}
          TF_VAR_domain_name: ${{ secrets.TF_VAR_DOMAIN_NAME }}
          TF_VAR_ssl_email: ${{ secrets.TF_VAR_SSL_EMAIL }}
          TF_VAR_github_token: ${{ secrets.GITHUB_TOKEN }}
          TF_VAR_github_username: ${{ secrets.TF_VAR_GITHUB_USERNAME }}
          TF_VAR_container_image_name: ${{ secrets.TF_VAR_CONTAINER_IMAGE_NAME }}
        run: |
          # Try to plan, and if it fails due to existing resources, attempt to import them
          if ! terraform plan -var-file="environments/prod.tfvars" -out=tfplan 2>&1 | tee plan_output.log; then
            echo "Plan failed, checking for existing resources..."

            # Check for resource group import needed
            if grep -q "habit-tracker-prod-rg.*already exists" plan_output.log; then
              echo "Importing existing resource group..."
              terraform import azurerm_resource_group.main /subscriptions/$(az account show --query id -o tsv)/resourceGroups/habit-tracker-prod-rg || true
            fi

            # Check for virtual network import needed
            if grep -q "habit-tracker-prod-vnet.*already exists" plan_output.log; then
              echo "Importing existing virtual network..."
              terraform import azurerm_virtual_network.main /subscriptions/$(az account show --query id -o tsv)/resourceGroups/habit-tracker-prod-rg/providers/Microsoft.Network/virtualNetworks/habit-tracker-prod-vnet || true
            fi

            # Check for public IP import needed
            if grep -q "habit-tracker-prod-pip.*already exists" plan_output.log; then
              echo "Importing existing public IP..."
              terraform import azurerm_public_ip.main /subscriptions/$(az account show --query id -o tsv)/resourceGroups/habit-tracker-prod-rg/providers/Microsoft.Network/publicIPAddresses/habit-tracker-prod-pip || true
            fi

            # Check for NSG import needed
            if grep -q "habit-tracker-prod-web-nsg.*already exists" plan_output.log; then
              echo "Importing existing network security group..."
              terraform import azurerm_network_security_group.web /subscriptions/$(az account show --query id -o tsv)/resourceGroups/habit-tracker-prod-rg/providers/Microsoft.Network/networkSecurityGroups/habit-tracker-prod-web-nsg || true
            fi

            # Check for private DNS zone import needed
            if grep -q "habit-tracker-prod-postgres.private.postgres.database.azure.com.*already exists" plan_output.log; then
              echo "Importing existing private DNS zone..."
              terraform import azurerm_private_dns_zone.postgres /subscriptions/$(az account show --query id -o tsv)/resourceGroups/habit-tracker-prod-rg/providers/Microsoft.Network/privateDnsZones/habit-tracker-prod-postgres.private.postgres.database.azure.com || true
            fi

            # Retry the plan after imports
            echo "Retrying plan after imports..."
            terraform plan -var-file="environments/prod.tfvars" -out=tfplan
          fi

          terraform show -no-color tfplan > plan.txt

      - name: Comment PR with Terraform Plan
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request'
        with:
          script: |
            const fs = require('fs');
            const plan = fs.readFileSync('terraform/plan.txt', 'utf8');
            const maxGitHubBodyCharacters = 65536;

            function chunkSubstr(str, size) {
              const numChunks = Math.ceil(str.length / size)
              const chunks = new Array(numChunks)
              for (let i = 0, o = 0; i < numChunks; ++i, o += size) {
                chunks[i] = str.substr(o, size)
              }
              return chunks
            }

            const planChunks = chunkSubstr(plan, maxGitHubBodyCharacters);

            for (let i = 0; i < planChunks.length; i++) {
              const output = `### Terraform Plan Part ${i + 1}

            \`\`\`terraform
            ${planChunks[i]}
            \`\`\`

            *Pusher: @${{ github.actor }}, Action: \`${{ github.event_name }}\`, Working Directory: \`terraform\`, Workflow: \`${{ github.workflow }}\`*`;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: output
              });
            }

      - name: Save Terraform Plan Summary
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
        run: |
          echo "## Terraform Plan Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment**: Production" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Plan Output" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          head -50 terraform/plan.txt >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Plan completed successfully. Ready for apply." >> $GITHUB_STEP_SUMMARY

  terraform-apply:
    needs: [docker-build]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    environment: production

    outputs:
      vm_ip: ${{ steps.terraform-output.outputs.vm_ip }}
      ssh_private_key: ${{ steps.terraform-output.outputs.ssh_private_key }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~1.0"
          terraform_wrapper: false

      - name: Validate Required Secrets
        run: |
          if [ -z "${{ secrets.AZURE_CREDENTIALS }}" ]; then
            echo "‚ùå AZURE_CREDENTIALS secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.TF_VAR_FLASK_SECRET_KEY }}" ]; then
            echo "‚ùå TF_VAR_FLASK_SECRET_KEY secret is not set"
            exit 1
          fi
          echo "‚úÖ Required secrets are configured"

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Import Existing Resources
        working-directory: terraform
        run: |
          echo "üîç Checking for existing resources to import..."
          chmod +x import-existing.sh
          ./import-existing.sh prod

      - name: Terraform Apply
        working-directory: terraform
        env:
          TF_VAR_flask_secret_key: ${{ secrets.TF_VAR_FLASK_SECRET_KEY }}
          TF_VAR_domain_name: ${{ secrets.TF_VAR_DOMAIN_NAME }}
          TF_VAR_ssl_email: ${{ secrets.TF_VAR_SSL_EMAIL }}
          TF_VAR_github_token: ${{ secrets.GITHUB_TOKEN }}
          TF_VAR_github_username: ${{ secrets.TF_VAR_GITHUB_USERNAME }}
          TF_VAR_container_image_name: ${{ secrets.TF_VAR_CONTAINER_IMAGE_NAME }}
        run: |
          echo "üöÄ Running Terraform apply..."
          if ! terraform apply -var-file="environments/prod.tfvars" -auto-approve; then
            echo "‚ùå Terraform apply failed"
            exit 1
          fi

          echo "‚úÖ Terraform apply completed successfully"

          # Verify key resources exist in state
          echo "üìã Verifying infrastructure state..."

          if ! terraform state show azurerm_public_ip.main >/dev/null 2>&1; then
            echo "‚ùå Public IP resource not found in state"
            exit 1
          fi

          if ! terraform state show azurerm_linux_virtual_machine.main >/dev/null 2>&1; then
            echo "‚ùå Virtual machine resource not found in state"
            exit 1
          fi

          echo "‚úÖ Key infrastructure resources verified in state"

          # Show current state for debugging
          echo "üîç Current Terraform state:"
          terraform state list

      - name: Upload Terraform State
        uses: actions/upload-artifact@v4
        with:
          name: terraform-state
          path: |
            terraform/terraform.tfstate
            terraform/.terraform/
          retention-days: 1

      - name: Wait for VM to be Ready
        working-directory: terraform
        run: |
          echo "‚è≥ Waiting for VM to be fully provisioned..."
          VM_IP=$(terraform output -raw public_ip_address 2>/dev/null || echo "")

          if [ -z "$VM_IP" ]; then
            echo "‚ùå Could not get VM IP from Terraform output"
            terraform output
            exit 1
          fi

          echo "üîç VM IP: $VM_IP"
          echo "‚è≥ Waiting for VM to respond to ping..."

          # Wait for VM to respond to ping (up to 5 minutes)
          for i in {1..30}; do
            if ping -c 1 -W 5 "$VM_IP" >/dev/null 2>&1; then
              echo "‚úÖ VM is responding to ping (attempt $i)"
              break
            else
              echo "‚è≥ VM not responding to ping yet... (attempt $i/30)"
              if [ $i -eq 30 ]; then
                echo "‚ö†Ô∏è VM not responding to ping after 5 minutes, but continuing..."
              fi
              sleep 10
            fi
          done

      - name: Get Terraform Outputs
        id: terraform-output
        working-directory: terraform
        run: |
          echo "üîç Getting Terraform outputs..."

          # Check if Terraform state exists
          if [ ! -f "terraform.tfstate" ] && [ ! -f ".terraform/terraform.tfstate" ]; then
            echo "‚ùå No Terraform state file found. Apply may have failed."
            exit 1
          fi

          # List all available outputs for debugging
          echo "üìã Available Terraform outputs:"
          terraform output || {
            echo "‚ùå Failed to get Terraform outputs"
            exit 1
          }

          # Get VM IP with error checking
          VM_IP=$(terraform output -raw public_ip_address 2>/dev/null || echo "")
          if [ -z "$VM_IP" ]; then
            echo "‚ùå Failed to get VM IP from Terraform output 'public_ip_address'"
            echo "Available outputs:"
            terraform output
            exit 1
          fi
          echo "‚úÖ VM IP: $VM_IP"
          echo "vm_ip=$VM_IP" >> $GITHUB_OUTPUT

          # Get SSH private key with error checking
          SSH_KEY=$(terraform output -raw ssh_private_key 2>/dev/null || echo "")
          if [ -z "$SSH_KEY" ]; then
            echo "‚ùå Failed to get SSH private key from Terraform output 'ssh_private_key'"
            exit 1
          fi
          echo "‚úÖ SSH key retrieved (length: $(echo "$SSH_KEY" | wc -c) characters)"
          echo "ssh_private_key<<EOF" >> $GITHUB_OUTPUT
          echo "$SSH_KEY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  deploy:
    needs: terraform-apply
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "~1.0"
          terraform_wrapper: false

      - name: Download Terraform State
        uses: actions/download-artifact@v4
        with:
          name: terraform-state
          path: terraform/

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Setup SSH key
        run: |
          VM_IP="${{ needs.terraform-apply.outputs.vm_ip }}"
          SSH_KEY="${{ needs.terraform-apply.outputs.ssh_private_key }}"

          if [ -z "$VM_IP" ]; then
            echo "‚ùå VM IP is empty. Terraform apply may have failed."
            exit 1
          fi

          if [ -z "$SSH_KEY" ]; then
            echo "‚ùå SSH private key is empty. Terraform apply may have failed."
            exit 1
          fi

          echo "‚úÖ VM IP: $VM_IP"
          echo "‚úÖ SSH key length: $(echo "$SSH_KEY" | wc -c) characters"

          # Setup SSH directory and key
          mkdir -p ~/.ssh
          echo "$SSH_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          chmod 700 ~/.ssh

          # Create SSH config for better connection handling
          cat > ~/.ssh/config << EOF
          Host vm
            HostName $VM_IP
            User azureuser
            IdentityFile ~/.ssh/id_rsa
            StrictHostKeyChecking no
            UserKnownHostsFile /dev/null
            ServerAliveInterval 60
            ServerAliveCountMax 3
            ConnectTimeout 30
          EOF
          chmod 600 ~/.ssh/config

          # Wait for VM SSH service to be ready
          echo "‚è≥ Waiting for VM SSH service to be ready..."
          for i in {1..20}; do
            if timeout 10 ssh -o ConnectTimeout=10 -o BatchMode=yes vm "echo 'SSH connection successful'" 2>/dev/null; then
              echo "‚úÖ SSH connection successful on attempt $i"
              break
            else
              echo "‚è≥ SSH not ready yet, retrying in 15 seconds... (attempt $i/20)"
              if [ $i -eq 20 ]; then
                echo "‚ùå SSH connection failed after 20 attempts"
                echo "üîç Debugging information:"
                echo "VM IP: $VM_IP"
                echo "Testing basic connectivity..."
                timeout 5 nc -zv "$VM_IP" 22 || echo "Port 22 not reachable"
                exit 1
              fi
              sleep 15
            fi
          done

          # Wait for VM initialization to complete
          echo "‚è≥ Waiting for VM initialization to complete..."
          for i in {1..15}; do
            if ssh vm "test -f /tmp/vm-ready" 2>/dev/null; then
              echo "‚úÖ VM initialization completed"
              ssh vm "cat /tmp/vm-ready"
              break
            else
              echo "‚è≥ VM still initializing... (attempt $i/15)"
              if [ $i -eq 15 ]; then
                echo "‚ö†Ô∏è VM initialization check timed out, but proceeding..."
                break
              fi
              sleep 20
            fi
          done

      - name: Create deployment environment file
        run: |
          echo "üîç Creating deployment environment file..."

          # Generate a secure database password
          DB_PASSWORD=$(openssl rand -base64 32)

          cat > .env.prod << EOF
          # Container Configuration
          CONTAINER_IMAGE=ghcr.io/${{ github.repository }}:${{ github.sha }}

          # Flask Configuration
          FLASK_ENV=production
          SECRET_KEY=${{ secrets.TF_VAR_FLASK_SECRET_KEY }}

          # Database Configuration (Docker PostgreSQL)
          DB_USER=habitadmin
          DB_PASSWORD=$DB_PASSWORD

          # Optional: PgAdmin Configuration
          PGADMIN_EMAIL=admin@${{ github.repository_owner }}.com
          PGADMIN_PASSWORD=$(openssl rand -base64 16)
          EOF

          echo "‚úÖ Environment file created with secure passwords"

      - name: Copy deployment files to VM
        run: |
          echo "üìÅ Copying deployment files to VM..."
          scp .env.prod vm:/tmp/
          scp docker-compose.yml vm:/tmp/
          scp docker-compose.prod.yml vm:/tmp/
          scp scripts/init-db.sql vm:/tmp/
          echo "‚úÖ Files copied successfully"

      - name: Deploy application with Docker Compose
        run: |
          echo "üöÄ Starting deployment on VM..."
          ssh vm << 'EOF'
            # Setup deployment directory
            sudo mkdir -p /opt/habit-tracker
            sudo cp /tmp/.env.prod /opt/habit-tracker/
            sudo cp /tmp/docker-compose.yml /opt/habit-tracker/
            sudo cp /tmp/docker-compose.prod.yml /opt/habit-tracker/
            sudo mkdir -p /opt/habit-tracker/scripts
            sudo cp /tmp/init-db.sql /opt/habit-tracker/scripts/
            cd /opt/habit-tracker

            # Login to GitHub Container Registry
            echo "${{ secrets.GITHUB_TOKEN }}" | sudo docker login ghcr.io -u ${{ github.actor }} --password-stdin

            # Stop existing services
            sudo docker compose -f docker-compose.yml -f docker-compose.prod.yml down || true

            # Pull latest images
            sudo docker compose -f docker-compose.yml -f docker-compose.prod.yml pull

            # Start services with production overrides
            sudo docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d

            # Wait for services to be healthy
            echo "‚è≥ Waiting for services to be healthy..."
            for i in {1..30}; do
              if sudo docker compose -f docker-compose.yml -f docker-compose.prod.yml ps | grep -q "healthy"; then
                echo "‚úÖ Services are healthy"
                break
              else
                echo "‚è≥ Waiting for services... (attempt $i/30)"
                sleep 10
              fi
            done

            # Test application
            sleep 10
            curl -f http://localhost:5000/ || exit 1
            echo "‚úÖ Application deployed successfully with Docker Compose!"
          EOF

      - name: Setup SSL Certificate (if domain configured)
        run: |
          if [ -z "${{ secrets.TF_VAR_DOMAIN_NAME }}" ]; then
            echo "TF_VAR_DOMAIN_NAME secret is not set. Skipping SSL setup."
            exit 0
          fi
          echo "üîí Setting up SSL certificate..."
          ssh vm << 'EOF'
            sudo sed -i "s/server_name _;/server_name ${{ secrets.TF_VAR_DOMAIN_NAME }};/g" /etc/nginx/sites-available/habit-tracker
            sudo nginx -t
            sudo systemctl reload nginx
            sudo certbot --nginx -d ${{ secrets.TF_VAR_DOMAIN_NAME }} --email ${{ secrets.TF_VAR_SSL_EMAIL }} --agree-tos --non-interactive
            echo "SSL certificate configured successfully!"
          EOF

      - name: Verify deployment
        run: |
          VM_IP=${{ needs.terraform-apply.outputs.vm_ip }}
          echo "Testing HTTP redirect..."
          curl -I http://$VM_IP | grep -q "301\|302" || echo "Warning: HTTP redirect not working"
          echo "Testing application health..."
          curl -f http://$VM_IP/ || curl -f https://$VM_IP/ || {
            echo "Application health check failed"
            exit 1
          }
          echo "Deployment verification completed successfully!"
          echo "Application is available at: http://$VM_IP"
          if [ -n "${{ secrets.TF_VAR_DOMAIN_NAME }}" ]; then
            echo "Domain URL: https://${{ secrets.TF_VAR_DOMAIN_NAME }}"
          fi

      - name: Cleanup
        if: always()
        run: |
          rm -f ~/.ssh/id_rsa
          rm -f .env.prod
